{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio classification through image classification:\n",
    "## Densely Connected Convolutional Networks\n",
    "\n",
    "This notebook shows how to implement and train [Densely Connected Convolutional Networks]( https://arxiv.org/pdf/1608.06993.pdf) on our audio dataset.   \n",
    "\n",
    "Advantage:\n",
    "\n",
    "- The advantage of this method is that it does not require any audio file feature engineering and nor it relies on the text that is associated with each audio recording. This means it can be faster and much cheaper.\n",
    "\n",
    "Disadvantage: \n",
    "\n",
    "- The accuracy on the current dataset is around 86% with overfitting, which is not unexpected since we have a very small dataset.    \n",
    "- Long tanning time with lots of learning rate annealing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import utils2; importlib.reload(utils2)\n",
    "from utils2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4870 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = image.ImageDataGenerator().flow_from_directory(current_dir+'/Data/maestroqa/train', \n",
    "                                                           target_size=(128,128),\n",
    "                                                           class_mode=None, \n",
    "                                                           shuffle=False,\n",
    "                                                           batch_size=1)\n",
    "trn_data = np.concatenate([batches.next() for i in range(batches.samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_batches = image.ImageDataGenerator().flow_from_directory(current_dir+'/Data/maestroqa/valid', \n",
    "                                                           target_size=(128,128),\n",
    "                                                           class_mode=None, \n",
    "                                                           shuffle=False,\n",
    "                                                           batch_size=1)\n",
    "val_data = np.concatenate([val_batches.next() for i in range(val_batches.samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trn_labels_1 = load_array(current_dir+'/Data/crop_data/models/trn_labels.bc')\n",
    "# val_labels_1 = load_array(current_dir+'/Data/crop_data/models/val_labels.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# val_classes = val_batches.classes\n",
    "# trn_classes = batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# val_classes.shape, val_data.shape, trn_classes.shape,trn_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trn_data_1 = load_array(current_dir+'/Data/crop_data/models/train_data_uu.bc')\n",
    "# val_data_1 = load_array(current_dir+'/Data/crop_data/models/valid_data_uu.bc')\n",
    "\n",
    "trn_labels_1 = load_array(current_dir+'/Data/crop_data/models/trn_labels_uu.bc')\n",
    "val_labels_1 = load_array(current_dir+'/Data/crop_data/models/val_labels_uu.bc')\n",
    "\n",
    "# print (trn_data_1.shape,val_data_1.shape, trn_labels_1.shape, val_labels_1.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_data = trn_data/255.\n",
    "val_data = val_data/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Densenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x): return Activation('relu')(x)\n",
    "def dropout(x, p): return Dropout(p)(x) if p else x\n",
    "def bn(x): return BatchNormalization(mode=0, axis=-1)(x)\n",
    "def relu_bn(x): return relu(bn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(x, nf, sz, wd, p):\n",
    "    x = Convolution2D(nf, sz, sz, init='he_uniform', border_mode='same', \n",
    "                          W_regularizer=l2(wd))(x)\n",
    "    return dropout(x,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_block(x, nf, bottleneck=False, p=None, wd=0):\n",
    "    x = relu_bn(x)\n",
    "    if bottleneck: x = relu_bn(conv(x, nf * 4, 1, wd, p))\n",
    "    return conv(x, nf, 3, wd, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_block(x, nb_layers, growth_rate, bottleneck=False, p=None, wd=0):\n",
    "    if bottleneck: nb_layers //= 2\n",
    "    for i in range(nb_layers):\n",
    "        b = conv_block(x, growth_rate, bottleneck=bottleneck, p=p, wd=wd)\n",
    "        x = merge([x,b], mode='concat', concat_axis=-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transition_block(x, compression=1.0, p=None, wd=0):\n",
    "    nf = int(x.get_shape().as_list()[-1] * compression)\n",
    "    x = relu_bn(x)\n",
    "    x = conv(x, nf, 1, wd, p)\n",
    "    return AveragePooling2D((2, 2), strides=(2, 2))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dense_net(nb_classes, img_input, depth=40, nb_block=3, \n",
    "     growth_rate=12, nb_filter=16, bottleneck=False, compression=1.0, p=None, wd=0, activation='softmax'):\n",
    "    \n",
    "    assert activation == 'softmax' or activation == 'sigmoid'\n",
    "    assert (depth - 4) % nb_block == 0\n",
    "    nb_layers_per_block = int((depth - 4) / nb_block)\n",
    "    nb_layers = [nb_layers_per_block] * nb_block\n",
    "\n",
    "    x = conv(img_input, nb_filter, 3, wd, 0)\n",
    "    for i,block in enumerate(nb_layers):\n",
    "        x = dense_block(x, block, growth_rate, bottleneck=bottleneck, p=p, wd=wd)\n",
    "        if i != len(nb_layers)-1:\n",
    "            x = transition_block(x, compression=compression, p=p, wd=wd)\n",
    "\n",
    "    x = relu_bn(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    return Dense(nb_classes, activation=activation, W_regularizer=l2(wd))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (128,128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_input = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sohrab/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_regularizer=<keras.reg..., kernel_initializer=\"he_uniform\")`\n",
      "  app.launch_new_instance()\n",
      "/home/sohrab/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=-1)`\n",
      "  app.launch_new_instance()\n",
      "/home/sohrab/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (1, 1), padding=\"same\", kernel_regularizer=<keras.reg..., kernel_initializer=\"he_uniform\")`\n",
      "  app.launch_new_instance()\n",
      "/home/sohrab/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), padding=\"same\", kernel_regularizer=<keras.reg..., kernel_initializer=\"he_uniform\")`\n",
      "  app.launch_new_instance()\n",
      "/home/sohrab/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/sohrab/anaconda3/lib/python3.5/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/sohrab/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(104, (1, 1), padding=\"same\", kernel_regularizer=<keras.reg..., kernel_initializer=\"he_uniform\")`\n",
      "  app.launch_new_instance()\n",
      "/home/sohrab/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(148, (1, 1), padding=\"same\", kernel_regularizer=<keras.reg..., kernel_initializer=\"he_uniform\")`\n",
      "  app.launch_new_instance()\n",
      "/home/sohrab/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, activation=\"softmax\", kernel_regularizer=<keras.reg...)`\n"
     ]
    }
   ],
   "source": [
    "x = create_dense_net(2, img_input, depth=100, nb_filter=16, compression=0.5, bottleneck=True, p=0.2, wd=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model(img_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "      optimizer=keras.optimizers.SGD(0.001, 0.9, nesterov=True), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 128, 128, 16) 448         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 128, 128, 16) 64          conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 128, 128, 16) 0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 128, 128, 48) 816         activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 128, 128, 48) 0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 128, 128, 48) 192         dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 128, 128, 48) 0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 128, 128, 12) 5196        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 128, 128, 12) 0           conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_49 (Merge)                (None, 128, 128, 28) 0           conv2d_100[0][0]                 \n",
      "                                                                 dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 128, 128, 28) 112         merge_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 128, 128, 28) 0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 128, 128, 48) 1392        activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 128, 128, 48) 0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 128, 128, 48) 192         dropout_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 128, 128, 48) 0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 128, 128, 12) 5196        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 128, 128, 12) 0           conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_50 (Merge)                (None, 128, 128, 40) 0           merge_49[0][0]                   \n",
      "                                                                 dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 128, 128, 40) 160         merge_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 128, 128, 40) 0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 128, 128, 48) 1968        activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 128, 128, 48) 0           conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 128, 128, 48) 192         dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 128, 128, 48) 0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 128, 128, 12) 5196        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 128, 128, 12) 0           conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_51 (Merge)                (None, 128, 128, 52) 0           merge_50[0][0]                   \n",
      "                                                                 dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 128, 128, 52) 208         merge_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 128, 128, 52) 0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 128, 128, 48) 2544        activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 128, 128, 48) 0           conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 128, 128, 48) 192         dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 128, 128, 48) 0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 128, 128, 12) 5196        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 128, 128, 12) 0           conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_52 (Merge)                (None, 128, 128, 64) 0           merge_51[0][0]                   \n",
      "                                                                 dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 128, 128, 64) 256         merge_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 128, 128, 64) 0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 128, 128, 48) 3120        activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 128, 128, 48) 0           conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 128, 128, 48) 192         dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 128, 128, 48) 0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 128, 128, 12) 5196        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, 128, 128, 12) 0           conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_53 (Merge)                (None, 128, 128, 76) 0           merge_52[0][0]                   \n",
      "                                                                 dropout_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 128, 128, 76) 304         merge_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 128, 128, 76) 0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 128, 128, 48) 3696        activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)           (None, 128, 128, 48) 0           conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 128, 128, 48) 192         dropout_109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 128, 128, 48) 0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 128, 128, 12) 5196        activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, 128, 128, 12) 0           conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_54 (Merge)                (None, 128, 128, 88) 0           merge_53[0][0]                   \n",
      "                                                                 dropout_110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 128, 128, 88) 352         merge_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 128, 128, 88) 0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 128, 128, 48) 4272        activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 128, 128, 48) 0           conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 128, 128, 48) 192         dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 128, 128, 48) 0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 128, 128, 12) 5196        activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 128, 128, 12) 0           conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_55 (Merge)                (None, 128, 128, 100 0           merge_54[0][0]                   \n",
      "                                                                 dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 128, 128, 100 400         merge_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 128, 128, 100 0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 128, 128, 48) 4848        activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 128, 128, 48) 0           conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 128, 128, 48) 192         dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 128, 128, 48) 0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 128, 128, 12) 5196        activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 128, 128, 12) 0           conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_56 (Merge)                (None, 128, 128, 112 0           merge_55[0][0]                   \n",
      "                                                                 dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 128, 128, 112 448         merge_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 128, 128, 112 0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 128, 128, 48) 5424        activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 128, 128, 48) 0           conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 128, 128, 48) 192         dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 128, 128, 48) 0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 128, 128, 12) 5196        activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)           (None, 128, 128, 12) 0           conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_57 (Merge)                (None, 128, 128, 124 0           merge_56[0][0]                   \n",
      "                                                                 dropout_116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 128, 128, 124 496         merge_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 128, 128, 124 0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 128, 128, 48) 6000        activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)           (None, 128, 128, 48) 0           conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 128, 128, 48) 192         dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 128, 128, 48) 0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 128, 128, 12) 5196        activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)           (None, 128, 128, 12) 0           conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_58 (Merge)                (None, 128, 128, 136 0           merge_57[0][0]                   \n",
      "                                                                 dropout_118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 128, 128, 136 544         merge_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 128, 128, 136 0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 128, 128, 48) 6576        activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)           (None, 128, 128, 48) 0           conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 128, 128, 48) 192         dropout_119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 128, 128, 48) 0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 128, 128, 12) 5196        activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 128, 128, 12) 0           conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_59 (Merge)                (None, 128, 128, 148 0           merge_58[0][0]                   \n",
      "                                                                 dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 128, 128, 148 592         merge_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 128, 128, 148 0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 128, 128, 48) 7152        activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 128, 128, 48) 0           conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 128, 128, 48) 192         dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 128, 128, 48) 0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 128, 128, 12) 5196        activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)           (None, 128, 128, 12) 0           conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_60 (Merge)                (None, 128, 128, 160 0           merge_59[0][0]                   \n",
      "                                                                 dropout_122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 128, 128, 160 640         merge_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 128, 128, 160 0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 128, 128, 48) 7728        activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)           (None, 128, 128, 48) 0           conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 128, 128, 48) 192         dropout_123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 128, 128, 48) 0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 128, 128, 12) 5196        activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)           (None, 128, 128, 12) 0           conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_61 (Merge)                (None, 128, 128, 172 0           merge_60[0][0]                   \n",
      "                                                                 dropout_124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 128, 128, 172 688         merge_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 128, 128, 172 0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 128, 128, 48) 8304        activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)           (None, 128, 128, 48) 0           conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 128, 128, 48) 192         dropout_125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 128, 128, 48) 0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 128, 128, 12) 5196        activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_126 (Dropout)           (None, 128, 128, 12) 0           conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_62 (Merge)                (None, 128, 128, 184 0           merge_61[0][0]                   \n",
      "                                                                 dropout_126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 128, 128, 184 736         merge_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 128, 128, 184 0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 128, 128, 48) 8880        activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_127 (Dropout)           (None, 128, 128, 48) 0           conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 128, 128, 48) 192         dropout_127[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 128, 128, 48) 0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 128, 128, 12) 5196        activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_128 (Dropout)           (None, 128, 128, 12) 0           conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_63 (Merge)                (None, 128, 128, 196 0           merge_62[0][0]                   \n",
      "                                                                 dropout_128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 128, 128, 196 784         merge_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 128, 128, 196 0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 128, 128, 48) 9456        activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_129 (Dropout)           (None, 128, 128, 48) 0           conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 128, 128, 48) 192         dropout_129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 128, 128, 48) 0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 128, 128, 12) 5196        activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_130 (Dropout)           (None, 128, 128, 12) 0           conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_64 (Merge)                (None, 128, 128, 208 0           merge_63[0][0]                   \n",
      "                                                                 dropout_130[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 128, 128, 208 832         merge_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 128, 128, 208 0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 128, 128, 104 21736       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)           (None, 128, 128, 104 0           conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 64, 64, 104)  0           dropout_131[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 64, 64, 104)  416         average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 64, 64, 104)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 64, 64, 48)   5040        activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_132 (Dropout)           (None, 64, 64, 48)   0           conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 64, 64, 48)   192         dropout_132[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 64, 64, 48)   0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 64, 64, 12)   5196        activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_133 (Dropout)           (None, 64, 64, 12)   0           conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_65 (Merge)                (None, 64, 64, 116)  0           average_pooling2d_3[0][0]        \n",
      "                                                                 dropout_133[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 64, 64, 116)  464         merge_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 64, 64, 116)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 64, 64, 48)   5616        activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_134 (Dropout)           (None, 64, 64, 48)   0           conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 64, 64, 48)   192         dropout_134[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 64, 64, 48)   0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 64, 64, 12)   5196        activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_135 (Dropout)           (None, 64, 64, 12)   0           conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_66 (Merge)                (None, 64, 64, 128)  0           merge_65[0][0]                   \n",
      "                                                                 dropout_135[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 64, 64, 128)  512         merge_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 64, 64, 128)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 64, 64, 48)   6192        activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)           (None, 64, 64, 48)   0           conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 64, 64, 48)   192         dropout_136[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 64, 64, 48)   0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 64, 64, 12)   5196        activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_137 (Dropout)           (None, 64, 64, 12)   0           conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_67 (Merge)                (None, 64, 64, 140)  0           merge_66[0][0]                   \n",
      "                                                                 dropout_137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 64, 64, 140)  560         merge_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 64, 64, 140)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 64, 64, 48)   6768        activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_138 (Dropout)           (None, 64, 64, 48)   0           conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 64, 64, 48)   192         dropout_138[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 64, 64, 48)   0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 64, 64, 12)   5196        activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_139 (Dropout)           (None, 64, 64, 12)   0           conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_68 (Merge)                (None, 64, 64, 152)  0           merge_67[0][0]                   \n",
      "                                                                 dropout_139[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 64, 64, 152)  608         merge_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 64, 64, 152)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 64, 64, 48)   7344        activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)           (None, 64, 64, 48)   0           conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 64, 64, 48)   192         dropout_140[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 64, 64, 48)   0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 64, 64, 12)   5196        activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_141 (Dropout)           (None, 64, 64, 12)   0           conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_69 (Merge)                (None, 64, 64, 164)  0           merge_68[0][0]                   \n",
      "                                                                 dropout_141[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 64, 64, 164)  656         merge_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 64, 64, 164)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 64, 64, 48)   7920        activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_142 (Dropout)           (None, 64, 64, 48)   0           conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 64, 64, 48)   192         dropout_142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 64, 64, 48)   0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 64, 64, 12)   5196        activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_143 (Dropout)           (None, 64, 64, 12)   0           conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_70 (Merge)                (None, 64, 64, 176)  0           merge_69[0][0]                   \n",
      "                                                                 dropout_143[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 64, 64, 176)  704         merge_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 64, 64, 176)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 64, 64, 48)   8496        activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_144 (Dropout)           (None, 64, 64, 48)   0           conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 64, 64, 48)   192         dropout_144[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 64, 64, 48)   0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 64, 64, 12)   5196        activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_145 (Dropout)           (None, 64, 64, 12)   0           conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_71 (Merge)                (None, 64, 64, 188)  0           merge_70[0][0]                   \n",
      "                                                                 dropout_145[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 64, 64, 188)  752         merge_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 64, 64, 188)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 64, 64, 48)   9072        activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_146 (Dropout)           (None, 64, 64, 48)   0           conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 64, 64, 48)   192         dropout_146[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 64, 64, 48)   0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 64, 64, 12)   5196        activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_147 (Dropout)           (None, 64, 64, 12)   0           conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_72 (Merge)                (None, 64, 64, 200)  0           merge_71[0][0]                   \n",
      "                                                                 dropout_147[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 64, 64, 200)  800         merge_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 64, 64, 200)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 64, 64, 48)   9648        activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_148 (Dropout)           (None, 64, 64, 48)   0           conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 64, 64, 48)   192         dropout_148[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 64, 64, 48)   0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 64, 64, 12)   5196        activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_149 (Dropout)           (None, 64, 64, 12)   0           conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_73 (Merge)                (None, 64, 64, 212)  0           merge_72[0][0]                   \n",
      "                                                                 dropout_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 64, 64, 212)  848         merge_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 64, 64, 212)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 64, 64, 48)   10224       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_150 (Dropout)           (None, 64, 64, 48)   0           conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 64, 64, 48)   192         dropout_150[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 64, 64, 48)   0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 64, 64, 12)   5196        activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_151 (Dropout)           (None, 64, 64, 12)   0           conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_74 (Merge)                (None, 64, 64, 224)  0           merge_73[0][0]                   \n",
      "                                                                 dropout_151[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 64, 64, 224)  896         merge_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 64, 64, 224)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 64, 64, 48)   10800       activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_152 (Dropout)           (None, 64, 64, 48)   0           conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 64, 64, 48)   192         dropout_152[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 64, 64, 48)   0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 64, 64, 12)   5196        activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_153 (Dropout)           (None, 64, 64, 12)   0           conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_75 (Merge)                (None, 64, 64, 236)  0           merge_74[0][0]                   \n",
      "                                                                 dropout_153[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 64, 64, 236)  944         merge_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 64, 64, 236)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 64, 64, 48)   11376       activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_154 (Dropout)           (None, 64, 64, 48)   0           conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 64, 64, 48)   192         dropout_154[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 64, 64, 48)   0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 64, 64, 12)   5196        activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_155 (Dropout)           (None, 64, 64, 12)   0           conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_76 (Merge)                (None, 64, 64, 248)  0           merge_75[0][0]                   \n",
      "                                                                 dropout_155[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 64, 64, 248)  992         merge_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 64, 64, 248)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 64, 64, 48)   11952       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_156 (Dropout)           (None, 64, 64, 48)   0           conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 64, 64, 48)   192         dropout_156[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 64, 64, 48)   0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 64, 64, 12)   5196        activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_157 (Dropout)           (None, 64, 64, 12)   0           conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_77 (Merge)                (None, 64, 64, 260)  0           merge_76[0][0]                   \n",
      "                                                                 dropout_157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 64, 64, 260)  1040        merge_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 64, 64, 260)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 64, 64, 48)   12528       activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_158 (Dropout)           (None, 64, 64, 48)   0           conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 64, 64, 48)   192         dropout_158[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 64, 64, 48)   0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 64, 64, 12)   5196        activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_159 (Dropout)           (None, 64, 64, 12)   0           conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_78 (Merge)                (None, 64, 64, 272)  0           merge_77[0][0]                   \n",
      "                                                                 dropout_159[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 64, 64, 272)  1088        merge_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 64, 64, 272)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 64, 64, 48)   13104       activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)           (None, 64, 64, 48)   0           conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 64, 64, 48)   192         dropout_160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 64, 64, 48)   0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 64, 64, 12)   5196        activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_161 (Dropout)           (None, 64, 64, 12)   0           conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_79 (Merge)                (None, 64, 64, 284)  0           merge_78[0][0]                   \n",
      "                                                                 dropout_161[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 64, 64, 284)  1136        merge_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 64, 64, 284)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 64, 64, 48)   13680       activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_162 (Dropout)           (None, 64, 64, 48)   0           conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 64, 64, 48)   192         dropout_162[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 64, 64, 48)   0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 64, 64, 12)   5196        activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_163 (Dropout)           (None, 64, 64, 12)   0           conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_80 (Merge)                (None, 64, 64, 296)  0           merge_79[0][0]                   \n",
      "                                                                 dropout_163[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 64, 64, 296)  1184        merge_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 64, 64, 296)  0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 64, 64, 148)  43956       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_164 (Dropout)           (None, 64, 64, 148)  0           conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 32, 32, 148)  0           dropout_164[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 32, 32, 148)  592         average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 32, 32, 148)  0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 32, 32, 48)   7152        activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_165 (Dropout)           (None, 32, 32, 48)   0           conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 32, 32, 48)   192         dropout_165[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 32, 32, 48)   0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 32, 32, 12)   5196        activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_166 (Dropout)           (None, 32, 32, 12)   0           conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_81 (Merge)                (None, 32, 32, 160)  0           average_pooling2d_4[0][0]        \n",
      "                                                                 dropout_166[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 32, 32, 160)  640         merge_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 32, 32, 160)  0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 32, 32, 48)   7728        activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_167 (Dropout)           (None, 32, 32, 48)   0           conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 32, 32, 48)   192         dropout_167[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 32, 32, 48)   0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 32, 32, 12)   5196        activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_168 (Dropout)           (None, 32, 32, 12)   0           conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_82 (Merge)                (None, 32, 32, 172)  0           merge_81[0][0]                   \n",
      "                                                                 dropout_168[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 32, 32, 172)  688         merge_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 32, 32, 172)  0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 32, 32, 48)   8304        activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_169 (Dropout)           (None, 32, 32, 48)   0           conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 32, 32, 48)   192         dropout_169[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 32, 32, 48)   0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 32, 32, 12)   5196        activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_170 (Dropout)           (None, 32, 32, 12)   0           conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_83 (Merge)                (None, 32, 32, 184)  0           merge_82[0][0]                   \n",
      "                                                                 dropout_170[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 32, 32, 184)  736         merge_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 32, 32, 184)  0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 32, 32, 48)   8880        activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_171 (Dropout)           (None, 32, 32, 48)   0           conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 32, 32, 48)   192         dropout_171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 32, 32, 48)   0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 32, 32, 12)   5196        activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_172 (Dropout)           (None, 32, 32, 12)   0           conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_84 (Merge)                (None, 32, 32, 196)  0           merge_83[0][0]                   \n",
      "                                                                 dropout_172[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 32, 32, 196)  784         merge_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 32, 32, 196)  0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 32, 32, 48)   9456        activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_173 (Dropout)           (None, 32, 32, 48)   0           conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 32, 32, 48)   192         dropout_173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 32, 32, 48)   0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 32, 32, 12)   5196        activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_174 (Dropout)           (None, 32, 32, 12)   0           conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_85 (Merge)                (None, 32, 32, 208)  0           merge_84[0][0]                   \n",
      "                                                                 dropout_174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 32, 32, 208)  832         merge_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 32, 32, 208)  0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 32, 32, 48)   10032       activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_175 (Dropout)           (None, 32, 32, 48)   0           conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 32, 32, 48)   192         dropout_175[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 32, 32, 48)   0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 32, 32, 12)   5196        activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)           (None, 32, 32, 12)   0           conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_86 (Merge)                (None, 32, 32, 220)  0           merge_85[0][0]                   \n",
      "                                                                 dropout_176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 32, 32, 220)  880         merge_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 32, 32, 220)  0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 32, 32, 48)   10608       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_177 (Dropout)           (None, 32, 32, 48)   0           conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 32, 32, 48)   192         dropout_177[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 32, 32, 48)   0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 32, 32, 12)   5196        activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_178 (Dropout)           (None, 32, 32, 12)   0           conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_87 (Merge)                (None, 32, 32, 232)  0           merge_86[0][0]                   \n",
      "                                                                 dropout_178[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 32, 32, 232)  928         merge_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 32, 32, 232)  0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 32, 32, 48)   11184       activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_179 (Dropout)           (None, 32, 32, 48)   0           conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 32, 32, 48)   192         dropout_179[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 32, 32, 48)   0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 32, 32, 12)   5196        activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_180 (Dropout)           (None, 32, 32, 12)   0           conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_88 (Merge)                (None, 32, 32, 244)  0           merge_87[0][0]                   \n",
      "                                                                 dropout_180[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 32, 32, 244)  976         merge_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 32, 32, 244)  0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 32, 32, 48)   11760       activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_181 (Dropout)           (None, 32, 32, 48)   0           conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 32, 32, 48)   192         dropout_181[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 32, 32, 48)   0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 32, 32, 12)   5196        activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_182 (Dropout)           (None, 32, 32, 12)   0           conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_89 (Merge)                (None, 32, 32, 256)  0           merge_88[0][0]                   \n",
      "                                                                 dropout_182[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 32, 32, 256)  1024        merge_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 32, 32, 256)  0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 32, 32, 48)   12336       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_183 (Dropout)           (None, 32, 32, 48)   0           conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 32, 32, 48)   192         dropout_183[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 32, 32, 48)   0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 32, 32, 12)   5196        activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_184 (Dropout)           (None, 32, 32, 12)   0           conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_90 (Merge)                (None, 32, 32, 268)  0           merge_89[0][0]                   \n",
      "                                                                 dropout_184[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 32, 32, 268)  1072        merge_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 32, 32, 268)  0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 32, 32, 48)   12912       activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_185 (Dropout)           (None, 32, 32, 48)   0           conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 32, 32, 48)   192         dropout_185[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 32, 32, 48)   0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 32, 32, 12)   5196        activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_186 (Dropout)           (None, 32, 32, 12)   0           conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_91 (Merge)                (None, 32, 32, 280)  0           merge_90[0][0]                   \n",
      "                                                                 dropout_186[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 32, 32, 280)  1120        merge_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 32, 32, 280)  0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 32, 32, 48)   13488       activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_187 (Dropout)           (None, 32, 32, 48)   0           conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 32, 32, 48)   192         dropout_187[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 32, 32, 48)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 32, 32, 12)   5196        activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_188 (Dropout)           (None, 32, 32, 12)   0           conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_92 (Merge)                (None, 32, 32, 292)  0           merge_91[0][0]                   \n",
      "                                                                 dropout_188[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 32, 32, 292)  1168        merge_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 32, 32, 292)  0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 32, 32, 48)   14064       activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_189 (Dropout)           (None, 32, 32, 48)   0           conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 32, 32, 48)   192         dropout_189[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 32, 32, 48)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 32, 32, 12)   5196        activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_190 (Dropout)           (None, 32, 32, 12)   0           conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_93 (Merge)                (None, 32, 32, 304)  0           merge_92[0][0]                   \n",
      "                                                                 dropout_190[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 32, 32, 304)  1216        merge_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 32, 32, 304)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 32, 32, 48)   14640       activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_191 (Dropout)           (None, 32, 32, 48)   0           conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 32, 32, 48)   192         dropout_191[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 32, 32, 48)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 32, 32, 12)   5196        activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_192 (Dropout)           (None, 32, 32, 12)   0           conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_94 (Merge)                (None, 32, 32, 316)  0           merge_93[0][0]                   \n",
      "                                                                 dropout_192[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 32, 32, 316)  1264        merge_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 32, 32, 316)  0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 32, 32, 48)   15216       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_193 (Dropout)           (None, 32, 32, 48)   0           conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 32, 32, 48)   192         dropout_193[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 32, 32, 48)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 32, 32, 12)   5196        activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_194 (Dropout)           (None, 32, 32, 12)   0           conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_95 (Merge)                (None, 32, 32, 328)  0           merge_94[0][0]                   \n",
      "                                                                 dropout_194[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 32, 32, 328)  1312        merge_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 32, 32, 328)  0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 32, 32, 48)   15792       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_195 (Dropout)           (None, 32, 32, 48)   0           conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 32, 32, 48)   192         dropout_195[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 32, 32, 48)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 32, 32, 12)   5196        activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_196 (Dropout)           (None, 32, 32, 12)   0           conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_96 (Merge)                (None, 32, 32, 340)  0           merge_95[0][0]                   \n",
      "                                                                 dropout_196[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 32, 32, 340)  1360        merge_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 32, 32, 340)  0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 340)          0           activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            682         global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 778,742\n",
      "Trainable params: 755,230\n",
      "Non-trainable params: 23,512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parms = {'verbose': 2, 'callbacks': [TQDMNotebookCallback()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4870 samples, validate on 800 samples\n",
      "Epoch 1/20\n",
      " - 306s - loss: 1.3510 - acc: 0.5012 - val_loss: 1.3300 - val_acc: 0.5050\n",
      "Epoch 2/20\n",
      "4864/|/[loss: 1.320, acc: 0.509] 100%|| 4864/4870 [04:54<00:00, 17.36it/s] - 296s - loss: 1.3199 - acc: 0.5097 - val_loss: 1.3209 - val_acc: 0.5112\n",
      "Epoch 3/20\n",
      " - 296s - loss: 1.3181 - acc: 0.5544 - val_loss: 1.3193 - val_acc: 0.5138\n",
      "Epoch 4/20\n",
      "4864/|/[loss: 1.318, acc: 0.573] 100%|| 4864/4870 [04:53<00:00, 17.24it/s] - 296s - loss: 1.3178 - acc: 0.5733 - val_loss: 1.3186 - val_acc: 0.5150\n",
      "Epoch 5/20\n",
      " - 297s - loss: 1.3174 - acc: 0.5729 - val_loss: 1.3173 - val_acc: 0.5212\n",
      "Epoch 6/20\n",
      " - 297s - loss: 1.3168 - acc: 0.5809 - val_loss: 1.3168 - val_acc: 0.4925\n",
      "Epoch 7/20\n",
      "4864/|/[loss: 1.317, acc: 0.581] 100%|| 4864/4870 [04:54<00:00, 17.24it/s] - 297s - loss: 1.3171 - acc: 0.5811 - val_loss: 1.3163 - val_acc: 0.4925\n",
      "Epoch 8/20\n",
      " - 296s - loss: 1.3166 - acc: 0.5776 - val_loss: 1.3154 - val_acc: 0.4938\n",
      "Epoch 9/20\n",
      "4864/|/[loss: 1.317, acc: 0.567] 100%|| 4864/4870 [04:52<00:00, 17.62it/s] - 296s - loss: 1.3167 - acc: 0.5674 - val_loss: 1.3149 - val_acc: 0.5112\n",
      "Epoch 10/20\n",
      "4864/|/[loss: 1.316, acc: 0.584] 100%|| 4864/4870 [04:56<00:00, 17.09it/s] - 297s - loss: 1.3160 - acc: 0.5842 - val_loss: 1.3147 - val_acc: 0.5162\n",
      "Epoch 11/20\n",
      " - 297s - loss: 1.3157 - acc: 0.5819 - val_loss: 1.3139 - val_acc: 0.5563\n",
      "Epoch 12/20\n",
      "4864/|/[loss: 1.315, acc: 0.594] 100%|| 4864/4870 [04:52<00:00, 17.21it/s] - 297s - loss: 1.3153 - acc: 0.5945 - val_loss: 1.3137 - val_acc: 0.5525\n",
      "Epoch 13/20\n",
      " - 296s - loss: 1.3155 - acc: 0.5879 - val_loss: 1.3132 - val_acc: 0.5550\n",
      "Epoch 14/20\n",
      " - 296s - loss: 1.3154 - acc: 0.5809 - val_loss: 1.3128 - val_acc: 0.5625\n",
      "Epoch 15/20\n",
      "4864/|/[loss: 1.316, acc: 0.580] 100%|| 4864/4870 [04:55<00:00, 17.13it/s] - 297s - loss: 1.3156 - acc: 0.5793 - val_loss: 1.3123 - val_acc: 0.5550\n",
      "Epoch 16/20\n",
      " - 297s - loss: 1.3151 - acc: 0.5906 - val_loss: 1.3123 - val_acc: 0.5550\n",
      "Epoch 17/20\n",
      " - 297s - loss: 1.3143 - acc: 0.5947 - val_loss: 1.3121 - val_acc: 0.5525\n",
      "Epoch 18/20\n",
      "4864/|/[loss: 1.315, acc: 0.577] 100%|| 4864/4870 [04:55<00:00, 17.13it/s] - 297s - loss: 1.3149 - acc: 0.5764 - val_loss: 1.3117 - val_acc: 0.5563\n",
      "Epoch 19/20\n",
      " - 297s - loss: 1.3139 - acc: 0.5795 - val_loss: 1.3115 - val_acc: 0.5687\n",
      "Epoch 20/20\n",
      "4864/|/[loss: 1.314, acc: 0.588] 100%|| 4864/4870 [04:52<00:00, 17.21it/s] - 296s - loss: 1.3142 - acc: 0.5881 - val_loss: 1.3114 - val_acc: 0.5737\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ef4cee75e10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn_data, \n",
    "          trn_labels_1, \n",
    "          batch_size = 8, \n",
    "          epochs = 20, \n",
    "          validation_data=(val_data, val_labels_1),\n",
    "          **parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4870 samples, validate on 800 samples\n",
      "Epoch 1/20\n",
      " - 296s - loss: 1.3130 - acc: 0.5612 - val_loss: 1.3186 - val_acc: 0.5713\n",
      "Epoch 2/20\n",
      "4864/|/[loss: 1.298, acc: 0.574] 100%|| 4864/4870 [04:54<00:00, 17.14it/s] - 297s - loss: 1.2978 - acc: 0.5745 - val_loss: 1.3149 - val_acc: 0.5787\n",
      "Epoch 3/20\n",
      " - 297s - loss: 1.2852 - acc: 0.5916 - val_loss: 1.4422 - val_acc: 0.5325\n",
      "Epoch 4/20\n",
      " - 297s - loss: 1.2805 - acc: 0.5914 - val_loss: 1.3629 - val_acc: 0.5625\n",
      "Epoch 5/20\n",
      "4864/|/[loss: 1.271, acc: 0.602] 100%|| 4864/4870 [04:54<00:00, 17.09it/s] - 297s - loss: 1.2712 - acc: 0.6025 - val_loss: 1.4226 - val_acc: 0.5475\n",
      "Epoch 6/20\n",
      " - 297s - loss: 1.2664 - acc: 0.6160 - val_loss: 1.3119 - val_acc: 0.6162\n",
      "Epoch 7/20\n",
      " - 296s - loss: 1.2537 - acc: 0.6236 - val_loss: 1.3710 - val_acc: 0.6000\n",
      "Epoch 8/20\n",
      "4864/|/[loss: 1.242, acc: 0.643] 100%|| 4864/4870 [04:54<00:00, 17.17it/s] - 296s - loss: 1.2416 - acc: 0.6431 - val_loss: 1.3501 - val_acc: 0.6175\n",
      "Epoch 9/20\n",
      " - 297s - loss: 1.2365 - acc: 0.6452 - val_loss: 1.3554 - val_acc: 0.5887\n",
      "Epoch 10/20\n",
      " - 297s - loss: 1.2226 - acc: 0.6593 - val_loss: 1.4088 - val_acc: 0.5725\n",
      "Epoch 11/20\n",
      "4864/|/[loss: 1.213, acc: 0.671] 100%|| 4864/4870 [04:55<00:00, 16.93it/s] - 297s - loss: 1.2132 - acc: 0.6706 - val_loss: 1.3483 - val_acc: 0.5813\n",
      "Epoch 12/20\n",
      " - 297s - loss: 1.2040 - acc: 0.6877 - val_loss: 1.8692 - val_acc: 0.5038\n",
      "Epoch 13/20\n",
      "4864/|/[loss: 1.183, acc: 0.699] 100%|| 4864/4870 [04:52<00:00, 17.17it/s] - 296s - loss: 1.1830 - acc: 0.6992 - val_loss: 1.5021 - val_acc: 0.5550\n",
      "Epoch 14/20\n",
      "4864/|/[loss: 1.168, acc: 0.713] 100%|| 4864/4870 [04:56<00:00, 17.46it/s] - 297s - loss: 1.1681 - acc: 0.7129 - val_loss: 1.6356 - val_acc: 0.5425\n",
      "Epoch 15/20\n",
      " - 297s - loss: 1.1430 - acc: 0.7267 - val_loss: 2.4270 - val_acc: 0.5000\n",
      "Epoch 16/20\n",
      "4864/|/[loss: 1.104, acc: 0.762] 100%|| 4864/4870 [04:53<00:00, 16.88it/s] - 297s - loss: 1.1035 - acc: 0.7618 - val_loss: 3.1067 - val_acc: 0.5000\n",
      "Epoch 17/20\n",
      "4864/|/[loss: 1.073, acc: 0.778] 100%|| 4864/4870 [04:56<00:00, 17.17it/s] - 297s - loss: 1.0725 - acc: 0.7784 - val_loss: 2.2196 - val_acc: 0.5000\n",
      "Epoch 18/20\n",
      " - 297s - loss: 1.0469 - acc: 0.7994 - val_loss: 2.3938 - val_acc: 0.5025\n",
      "Epoch 19/20\n",
      "4864/|/[loss: 1.012, acc: 0.825] 100%|| 4864/4870 [04:53<00:00, 17.36it/s] - 297s - loss: 1.0114 - acc: 0.8248 - val_loss: 2.4867 - val_acc: 0.5000\n",
      "Epoch 20/20\n",
      "4864/|/[loss: 0.962, acc: 0.854] 100%|| 4864/4870 [04:56<00:00, 17.26it/s] - 297s - loss: 0.9623 - acc: 0.8540 - val_loss: 3.1048 - val_acc: 0.5075\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ef4abb46828>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 0.001)\n",
    "model.fit(trn_data, \n",
    "          trn_labels_1, \n",
    "          batch_size = 8, \n",
    "          epochs = 20, \n",
    "          validation_data=(val_data, val_labels_1),\n",
    "          **parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4870 samples, validate on 800 samples\n",
      "Epoch 1/20\n",
      " - 297s - loss: 0.9262 - acc: 0.8678 - val_loss: 2.0112 - val_acc: 0.5188\n",
      "Epoch 2/20\n",
      "4864/|/[loss: 0.915, acc: 0.879] 100%|| 4864/4870 [04:53<00:00, 17.22it/s] - 297s - loss: 0.9148 - acc: 0.8791 - val_loss: 1.8506 - val_acc: 0.5275\n",
      "Epoch 3/20\n",
      "4864/|/[loss: 0.898, acc: 0.894] 100%|| 4864/4870 [04:56<00:00, 17.02it/s] - 297s - loss: 0.8978 - acc: 0.8940 - val_loss: 2.0132 - val_acc: 0.5100\n",
      "Epoch 4/20\n",
      " - 297s - loss: 0.9083 - acc: 0.8797 - val_loss: 1.8734 - val_acc: 0.5262\n",
      "Epoch 5/20\n",
      "4864/|/[loss: 0.902, acc: 0.880] 100%|| 4864/4870 [04:53<00:00, 17.24it/s] - 297s - loss: 0.9024 - acc: 0.8805 - val_loss: 1.9498 - val_acc: 0.5200\n",
      "Epoch 6/20\n",
      " - 297s - loss: 0.8822 - acc: 0.8947 - val_loss: 1.8458 - val_acc: 0.5225\n",
      "Epoch 7/20\n",
      " - 297s - loss: 0.8981 - acc: 0.8828 - val_loss: 1.7298 - val_acc: 0.5525\n",
      "Epoch 8/20\n",
      "4864/|/[loss: 0.895, acc: 0.886] 100%|| 4864/4870 [04:54<00:00, 16.90it/s] - 297s - loss: 0.8948 - acc: 0.8864 - val_loss: 1.6729 - val_acc: 0.5663\n",
      "Epoch 9/20\n",
      " - 297s - loss: 0.8836 - acc: 0.8932 - val_loss: 1.7117 - val_acc: 0.5425\n",
      "Epoch 10/20\n",
      " - 297s - loss: 0.8781 - acc: 0.8967 - val_loss: 1.7320 - val_acc: 0.5375\n",
      "Epoch 11/20\n",
      "4864/|/[loss: 0.867, acc: 0.899] 100%|| 4864/4870 [04:54<00:00, 17.31it/s] - 297s - loss: 0.8670 - acc: 0.8996 - val_loss: 1.6024 - val_acc: 0.5800\n",
      "Epoch 12/20\n",
      " - 297s - loss: 0.8694 - acc: 0.9031 - val_loss: 1.6951 - val_acc: 0.5575\n",
      "Epoch 13/20\n",
      " - 297s - loss: 0.8618 - acc: 0.9043 - val_loss: 1.5901 - val_acc: 0.5763\n",
      "Epoch 14/20\n",
      "4864/|/[loss: 0.864, acc: 0.904] 100%|| 4864/4870 [04:54<00:00, 17.26it/s] - 297s - loss: 0.8642 - acc: 0.9037 - val_loss: 1.4974 - val_acc: 0.5887\n",
      "Epoch 15/20\n",
      " - 297s - loss: 0.8653 - acc: 0.9002 - val_loss: 1.4551 - val_acc: 0.6050\n",
      "Epoch 16/20\n",
      " - 297s - loss: 0.8588 - acc: 0.9068 - val_loss: 1.4510 - val_acc: 0.6025\n",
      "Epoch 17/20\n",
      "4864/|/[loss: 0.860, acc: 0.906] 100%|| 4864/4870 [04:54<00:00, 17.42it/s] - 296s - loss: 0.8601 - acc: 0.9062 - val_loss: 1.4311 - val_acc: 0.6025\n",
      "Epoch 18/20\n",
      " - 297s - loss: 0.8618 - acc: 0.9000 - val_loss: 1.4003 - val_acc: 0.6212\n",
      "Epoch 19/20\n",
      " - 297s - loss: 0.8531 - acc: 0.9068 - val_loss: 1.7011 - val_acc: 0.5587\n",
      "Epoch 20/20\n",
      "4864/|/[loss: 0.843, acc: 0.905] 100%|| 4864/4870 [04:55<00:00, 17.34it/s] - 297s - loss: 0.8430 - acc: 0.9047 - val_loss: 1.3752 - val_acc: 0.6250\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ef4ab9ecd30>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 0.0001)\n",
    "model.fit(trn_data, \n",
    "          trn_labels_1, \n",
    "          batch_size = 8, \n",
    "          epochs = 20, \n",
    "          validation_data=(val_data, val_labels_1),\n",
    "          **parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4870 samples, validate on 800 samples\n",
      "Epoch 1/20\n",
      "4864/|/[loss: 0.839, acc: 0.916] 100%|| 4864/4870 [04:30<00:00, 18.80it/s] - 273s - loss: 0.8388 - acc: 0.9162 - val_loss: 1.8378 - val_acc: 0.5250\n",
      "Epoch 2/20\n",
      " - 273s - loss: 0.8193 - acc: 0.9201 - val_loss: 2.3030 - val_acc: 0.5075\n",
      "Epoch 3/20\n",
      " - 273s - loss: 0.8112 - acc: 0.9193 - val_loss: 1.3588 - val_acc: 0.6613\n",
      "Epoch 4/20\n",
      "4864/|/[loss: 0.790, acc: 0.930] 100%|| 4864/4870 [04:31<00:00, 18.65it/s] - 273s - loss: 0.7901 - acc: 0.9296 - val_loss: 1.2102 - val_acc: 0.6750\n",
      "Epoch 5/20\n",
      " - 273s - loss: 0.7801 - acc: 0.9390 - val_loss: 1.6928 - val_acc: 0.5425\n",
      "Epoch 6/20\n",
      " - 274s - loss: 0.7696 - acc: 0.9462 - val_loss: 3.2443 - val_acc: 0.5000\n",
      "Epoch 7/20\n",
      "4864/|/[loss: 0.763, acc: 0.939] 100%|| 4864/4870 [04:32<00:00, 18.67it/s] - 273s - loss: 0.7631 - acc: 0.9386 - val_loss: 1.6343 - val_acc: 0.5725\n",
      "Epoch 8/20\n",
      " - 273s - loss: 0.7555 - acc: 0.9452 - val_loss: 1.3053 - val_acc: 0.6350\n",
      "Epoch 9/20\n",
      " - 273s - loss: 0.7475 - acc: 0.9456 - val_loss: 2.5227 - val_acc: 0.5062\n",
      "Epoch 10/20\n",
      "4864/|/[loss: 0.749, acc: 0.947] 100%|| 4864/4870 [04:32<00:00, 18.70it/s] - 273s - loss: 0.7490 - acc: 0.9464 - val_loss: 1.3575 - val_acc: 0.6150\n",
      "Epoch 11/20\n",
      " - 273s - loss: 0.7426 - acc: 0.9462 - val_loss: 1.3432 - val_acc: 0.6250\n",
      "Epoch 12/20\n",
      " - 273s - loss: 0.7223 - acc: 0.9538 - val_loss: 1.3391 - val_acc: 0.6275\n",
      "Epoch 13/20\n",
      " - 273s - loss: 0.7282 - acc: 0.9532 - val_loss: 1.6958 - val_acc: 0.5500\n",
      "Epoch 14/20\n",
      "4864/|/[loss: 0.721, acc: 0.953] 100%|| 4864/4870 [04:30<00:00, 18.76it/s] - 273s - loss: 0.7206 - acc: 0.9530 - val_loss: 1.3252 - val_acc: 0.6000\n",
      "Epoch 15/20\n",
      " - 273s - loss: 0.7079 - acc: 0.9608 - val_loss: 1.1581 - val_acc: 0.7175\n",
      "Epoch 16/20\n",
      " - 273s - loss: 0.7067 - acc: 0.9608 - val_loss: 1.3385 - val_acc: 0.6288\n",
      "Epoch 17/20\n",
      "4864/|/[loss: 0.693, acc: 0.964] 100%|| 4864/4870 [04:32<00:00, 18.84it/s] - 273s - loss: 0.6935 - acc: 0.9639 - val_loss: 1.3782 - val_acc: 0.6300\n",
      "Epoch 18/20\n",
      "4864/|/[loss: 0.695, acc: 0.966] 100%|| 4864/4870 [04:29<00:00, 18.89it/s] - 273s - loss: 0.6953 - acc: 0.9663 - val_loss: 2.0046 - val_acc: 0.5238\n",
      "Epoch 19/20\n",
      " - 273s - loss: 0.6926 - acc: 0.9639 - val_loss: 2.2950 - val_acc: 0.5138\n",
      "Epoch 20/20\n",
      " - 273s - loss: 0.6894 - acc: 0.9655 - val_loss: 2.0181 - val_acc: 0.5400\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ef4ab94a7b8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 0.001)\n",
    "model.fit(trn_data, \n",
    "          trn_labels_1, \n",
    "          batch_size = 16, \n",
    "          epochs = 20, \n",
    "          validation_data=(val_data, val_labels_1),\n",
    "          **parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4870 samples, validate on 800 samples\n",
      "Epoch 1/20\n",
      " - 297s - loss: 0.7189 - acc: 0.9577 - val_loss: 1.2898 - val_acc: 0.6462\n",
      "Epoch 2/20\n",
      "4864/|/[loss: 0.703, acc: 0.964] 100%|| 4864/4870 [04:53<00:00, 17.26it/s] - 296s - loss: 0.7031 - acc: 0.9639 - val_loss: 1.1475 - val_acc: 0.7175\n",
      "Epoch 3/20\n",
      " - 297s - loss: 0.7077 - acc: 0.9618 - val_loss: 1.2388 - val_acc: 0.6813\n",
      "Epoch 4/20\n",
      " - 297s - loss: 0.6875 - acc: 0.9674 - val_loss: 1.0301 - val_acc: 0.7850\n",
      "Epoch 5/20\n",
      "4864/|/[loss: 0.700, acc: 0.959] 100%|| 4864/4870 [04:54<00:00, 17.32it/s] - 297s - loss: 0.7002 - acc: 0.9595 - val_loss: 1.0654 - val_acc: 0.7600\n",
      "Epoch 6/20\n",
      " - 297s - loss: 0.6952 - acc: 0.9624 - val_loss: 1.0085 - val_acc: 0.7863\n",
      "Epoch 7/20\n",
      " - 297s - loss: 0.6846 - acc: 0.9713 - val_loss: 1.1108 - val_acc: 0.7350\n",
      "Epoch 8/20\n",
      "4864/|/[loss: 0.688, acc: 0.964] 100%|| 4864/4870 [04:55<00:00, 17.18it/s] - 297s - loss: 0.6875 - acc: 0.9641 - val_loss: 1.0658 - val_acc: 0.7550\n",
      "Epoch 9/20\n",
      " - 297s - loss: 0.6873 - acc: 0.9667 - val_loss: 0.9861 - val_acc: 0.8163\n",
      "Epoch 10/20\n",
      " - 297s - loss: 0.6794 - acc: 0.9696 - val_loss: 0.9931 - val_acc: 0.8200\n",
      "Epoch 11/20\n",
      "4864/|/[loss: 0.712, acc: 0.960] 100%|| 4864/4870 [04:55<00:00, 17.33it/s] - 296s - loss: 0.7117 - acc: 0.9600 - val_loss: 0.9610 - val_acc: 0.8337\n",
      "Epoch 12/20\n",
      " - 296s - loss: 0.6852 - acc: 0.9682 - val_loss: 1.0319 - val_acc: 0.7788\n",
      "Epoch 13/20\n",
      "4864/|/[loss: 0.682, acc: 0.966] 100%|| 4864/4870 [04:52<00:00, 17.48it/s] - 296s - loss: 0.6816 - acc: 0.9661 - val_loss: 0.9802 - val_acc: 0.8200\n",
      "Epoch 14/20\n",
      " - 297s - loss: 0.6915 - acc: 0.9655 - val_loss: 1.0181 - val_acc: 0.7850\n",
      "Epoch 15/20\n",
      " - 296s - loss: 0.7018 - acc: 0.9651 - val_loss: 0.9875 - val_acc: 0.8112\n",
      "Epoch 16/20\n",
      "4864/|/[loss: 0.702, acc: 0.964] 100%|| 4864/4870 [04:54<00:00, 17.02it/s] - 297s - loss: 0.7014 - acc: 0.9645 - val_loss: 0.9445 - val_acc: 0.8425\n",
      "Epoch 17/20\n",
      " - 297s - loss: 0.6755 - acc: 0.9721 - val_loss: 0.9698 - val_acc: 0.8350\n",
      "Epoch 18/20\n",
      " - 297s - loss: 0.6752 - acc: 0.9723 - val_loss: 1.0209 - val_acc: 0.7975\n",
      "Epoch 19/20\n",
      "4864/|/[loss: 0.693, acc: 0.965] 100%|| 4864/4870 [04:54<00:00, 17.08it/s] - 296s - loss: 0.6930 - acc: 0.9651 - val_loss: 0.9500 - val_acc: 0.8488\n",
      "Epoch 20/20\n",
      " - 297s - loss: 0.6801 - acc: 0.9694 - val_loss: 0.9399 - val_acc: 0.8625\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ef4ab900cc0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 0.0001)\n",
    "model.fit(trn_data, \n",
    "          trn_labels_1, \n",
    "          batch_size = 8, \n",
    "          epochs = 20, \n",
    "          validation_data=(val_data, val_labels_1),\n",
    "          **parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "05626d9a5e2541189347906b96e84d1a": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "05d9ece9a3654725a111c74f49cb32f9": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "075197a807f54468b7188fbcee9b02fc": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "0ab4cecd4f924751bffd40f9cc88cd85": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "14909a3bfefa46459ba2e2b50101215a": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "1590afb64bb9419098f91c770f69c156": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "15d89c87ce304369b3097655ac005410": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "15fe2fa23f35452da26b66c33f05cb52": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "163353cc05174b4cacb84b63e1dbeb6d": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "175959110155423da9706f977c68bd9c": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "1768f0cc07624edb8e8f709f0b2c341a": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "176f9f91b6fb43e2a79dec41bf363dff": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "18a80cda63d442f48c22a28139247795": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "1b5be3ca48e3497989a43927570c65f1": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "1c894f0e9e64414badc9af5669e9fec1": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "213621f4db34406795376a2678095f05": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "21a27f9d0cb54c82a3b15cff9871c0df": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "22b7bed6daf24ea793f9bc24d601ff3a": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "23b0f2c127ea42c789e449f616aa723f": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "26708e4e489b4414976a9aa31719343d": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "28e0e1f694a34e9bbd8e8884aa22ba39": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "29086d5243b546f984883ce33276527d": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "2a2b7ad6340c410db2eec8bb9f53716f": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "2c4504fd2dbb478c985340ebc7753df9": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "2e22452a915d4c26b6865bd5f12ec20c": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "2f2de9133a7341b98729381e4e39dfcd": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "33aad662be0549cd8f0cd3ae6d140630": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "368d3bd7f3f248f8acd846685095f3e8": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "385c114267a149b1bbeb99631f4155ab": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "3921fe7b98b4444494f3979289844a75": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "3a10ccc4a96342c38664982b2922d0b8": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "3c0e74c8aec647fc8a959253fbb1236b": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "3f27aeef2ff445d986c527ca16bff87c": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "3fd26a27333c43488b809b507d624381": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "46fd141c689545c8bb5b8aeaeba76b76": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "4bb7245273c44bbfb7e87310de102948": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "4c877490cb344f3e916004271b842a3f": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "55569b1d901b42158a6e5b2758de3514": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "572d53d6f389498b93156cd14155bea4": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "57b3c24f2f7542d7a349121bf088dbe9": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "58d23262ae67410ea6928b3997e4ba24": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "590dd29e9d7542dc820585cd890f1778": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "599d637107e54c6998272c82a824e091": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "5f034af8ed9f443ca96e930d5d1a640c": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "60b475befc1247bf9a845021a60265ef": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "65e8bf1bdc49459cb01e27d966f5952f": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "66dcb70ab6cb4c6286959358b00ea4ca": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "6e33b05a6fe74f89b7882fde7790eaff": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "73d2a4d023cc4023acddda18e9e0c2a5": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "73d77edf84a94751b004b01249dcdb0c": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "74361ba1d9fd4d01b7ad1761604feef0": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "771f7d5260f34ac9b2e359da64962cf6": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "7a89c8030fc847c3b2b8922bcc07b704": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "7cb37163f57549ed888325b5a6889aae": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "7ce0e1add68142e1987f1840d1b01631": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "7e4b305fc1e14f8288d41417a295c564": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "7ea4d51d1fe04c0387484b752f8ad8c2": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "81a5545f39924ce7a88dad14ba636f2d": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "87d9adc21acf46ab92b5514636174438": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "880adf3cb8664542adce3c4085d9573b": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "8936dda98aad4fe095f7d30364ca39ad": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "8a89577e737d44a988e1b7a50396308f": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "8d6b46c13fed4e65a38024543efc398c": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "985a0d3410b64e4682cdeba677efec9a": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "989e36d4634d41f5a3231e04d756cabe": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "99ad7d9537d745fdb8f25aae1f6e7e8e": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "a91688a686694539a61d23f6b6f9819a": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "a95f72021f494b2fabc996707452bc30": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "aa32fef5b9184d3ca722cf3403c1ccf0": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "b1d2fcde7b2a447db35e981f97fa6d55": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "b5d50d4d355e4af48245df5c28c7b21e": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "b6cc3fbee38a4261847efab810a090b5": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "b73bd8afc7f6412085eaa2b77fd49922": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "b8cd6fd20f5742f0a6cb99f10679a3b0": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "b9aa9e9644164551a1649ec67fc977e4": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "bb9d034433fb427ca5f913869c633e31": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "bc38db175693403a887d2fccedc8a8c2": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "bf865f12be9a4a378740ecc827362dc9": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "c0e4f0bfe6c4441484a5a11e2ce696e7": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "c162e658455741de84918baaf6007433": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "c6a0d997276547c69f087612222ebe65": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "c6b9bb85d4e043df8369ec79b3ec1cc1": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "c8c7462a7e044e8d9bd5fee7b56b39c4": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "cb9ae2b5a8f0434d8a0e170a3e9e26b3": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "cc7c32be100543798147da7f85c09248": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "ce227a27ca9947e093994cb1c1108318": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "cef1b5c8c22e4cc790743ea2459d85a7": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "d400e029cfb74ed4aafe1a645aed6fd0": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "dbde52b488854c0aaccb145fb655cc16": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "dd1e2e84a9ad4cb1bf1f1acf3d7a3fa8": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "ddaeeefc1a9d4a83a472339e96063e64": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "ddb317348b6040ee8dea4df79743a9ac": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "df4dd4677e334dcc8d80df342befbe92": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "dfdb46a7b1a444739a24cc3877e850c1": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "e00a5752036c41f69801f29ad8d04fa7": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "e2d0cfdf0d4043ab8614163c4abd68c3": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "e4e8debf8b3f422aa2dce2c65c8e9611": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "e5680e70cd0248339b7b54ace0453675": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "e6cc84176f7b46e190aeff1f9c71a965": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "e7bc94992f2745a7be3fc4347fca980b": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "e9239902806a4a6fa0c33817df8a07c5": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "ebf6e1139f8c436d829ce134bfa664c8": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "ee72ab0424df487cb0682128f8eb0794": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "eff2cac4617f4f58bb5733573ed5dfaf": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "f2b8a9804af14aadb46c382c28058b6a": {
     "views": [
      {
       "cell_index": 28
      }
     ]
    },
    "f2ba534e0ee64439bf2d9776f8378f1a": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "f75e31826cfb4a5b994fba16e58d80f7": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "f9dacebac8f4478ca0785edd683f3088": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "fc84e80023a7471f934318f94b397e57": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
